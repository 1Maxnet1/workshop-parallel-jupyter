{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106f1e07-a319-4d03-88a9-f621ca802319",
   "metadata": {},
   "source": [
    "<img src=\"images/bwHPC_Logo_cmyk.svg\" width=\"200\" /> <img src=\"images/HochschuleEsslingen_Logo_RGB_DE.png\" width=\"200\" /> <img src=\"images/Konstanz_Logo.svg\" width=\"200\" /> <img src=\"images/KIT_Logo.png\" width=\"200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9f69d-37f4-4bd2-add9-1fb377df269c",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "Dask baut auf bewährten Modulen auf und erweitert diese um Möglichkeiten zur massiven Parallelisierung. So können mehrere NumPy Arrays oder Pandas Dataframes in entsprechenden Dask-Objekten zusammengefasst und für parallele Operationen bereitgestellt werden. Die Dask Objekte stellen große Teile der bakannten API (identisch zu NumPy Arrays oder Pandas Dataframes) bereit.\n",
    "\n",
    "Dabei kann Dask auch Daten in Objekten ablegen deren Größe den verfügbaren Arbeitsspeicher übersteigt. Hierfür lagert Dask teile der Daten in ein verfügbares File System aus. Dask kann daher genutzt werden, um Datenmengen zu verarbeiten, die für Pandas oder NumPy eigentlich zu groß sind. Sind jedoch nur wenige Daten zu verarbeiten/analysieren so kann der für Dask notwendige Overhead zu einer Verlangsamung im Vergleich zu reinen NumPy/Pandas Objekten führen.\n",
    "\n",
    "![image](images/Dask_Scale.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79069453-8eba-4f9e-9d7c-9e547c71adbb",
   "metadata": {},
   "source": [
    "## Dask Dashboard\n",
    "\n",
    "Eine Übersicht über die von Dask gestarteten Parallelen Vorgänge und die Auslastung der über Dask reservierten Ressourcen kann über das Dask Dashboard eingesehen werden. Das Client Objekt aus dem dask.distributed Modul ermöglicht das Starten eines Dask Dashboards. Wird das initialisierte Client Objekt ausgegeben, so enthält die Ausgabe eine URL unter der das gestartete Dashboard abgerufen werden kann.\n",
    "\n",
    "Wenn Jupter in Version 3.0 installiert ist oder zusätzlich Node.js (Version >= 12.0.0) und npm installiert sind, kann alternativ zur manuellen Nutzung auch das dask-labextensions Plugin in Jupyter installiert werden. Dies sorgt für eine Integration des Dask Dashboards in die Jupyter Oberfläche. Am linken Rand ist dann eine neue Schaltfläche \"Dask\" vorhanden. Über dies kann das Dask Dashboard erreicht werden, ohne dass hierfür eine separate URL aufgerufen werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff6906-cf60-4a98-acc8-6dbc27af1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(processes=False, threads_per_worker=4,\n",
    "                n_workers=1, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fecd4-19ff-4c56-a75a-f7855f0383aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54da4cf",
   "metadata": {},
   "source": [
    "Aktuell funktioniert das dask-labextensions Plugin am bwUniCluster noch nicht zusmmen mit dask-mpi. Alternativ kann wie oben beschrieben direkt die URL des Dashboards genutzt werden. Hierfür muss über ssh der Port aus der URL aus dem Cluster nach außen weitergeleitet werden. Dies kann mit folgendem Befehl lokal am genutzten Rechner in einer Konsole durchgeführt werden. Der Port und die IP des Jupyter-Compute-Node können dabei der Dashboard-URL entnommen werden.\n",
    "\n",
    "```bash\n",
    "ssh -N -L <Port>:<Jupyter-Compute-Node>:<Port> <Hochschulkürzel>_<User-ID>@bwunicluster.scc.kit.edu\n",
    "```\n",
    "\n",
    "Beispiel:\n",
    "```bash\n",
    "ssh -N -L 8787:10.0.1.112:8787 es_pkoester@bwunicluster.scc.kit.edu\n",
    "```\n",
    "\n",
    "Nach Ausführen des ssh-Port-Forwardings kann am lokalen Rechner das Dask-Dashboard unter\n",
    "\n",
    "```bash\n",
    "http://localhost:<Port>/status\n",
    "```\n",
    "\n",
    "aufgerufen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5783e1a-ee9a-48a5-889a-93fce54783a2",
   "metadata": {},
   "source": [
    "## Dask Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c89e3-065b-4dbc-82ab-225984e5ca74",
   "metadata": {},
   "source": [
    "Dask Array koordiniert mehrere NumPy Arrays und verteilt diese auf die zur Verfügung stehenden Ressourcen. So können Operationen verteilt auf mehrere Threads, Prozesse oder gar Nodes ausgeführt werden. Welche Operationen dabei möglich sind (welche Teile der NumPy Array API auch von Dask Array angeboten werden) kann der Dokumentation entnommen werden: https://docs.dask.org/en/latest/array-api.html.\n",
    "\n",
    "Weitere Beispiele zu Dask Array: https://mybinder.org/v2/gh/dask/dask-examples/main?urlpath=lab/tree/array.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2814e04-b220-4a28-bdbf-67872d154bc5",
   "metadata": {},
   "source": [
    "## Dask Dataframe\n",
    "\n",
    "Was Dask Array für NumPy Arrays ist (s.o.), dass ist Dask Dataframe für Pandas Dataframe. Die auf einem Dask Dataframe möglichen Operationen können der Dokumentation entnommen werden: https://docs.dask.org/en/latest/dataframe-api.html.\n",
    "\n",
    "Eine generelle Übersicht über sinnvolle und weniger sinnvolle Arten einen Dask Dataframe zu nutzen ist unter https://docs.dask.org/en/latest/dataframe.html zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24fb48",
   "metadata": {},
   "source": [
    "## Dask und SLURM\n",
    "\n",
    "Um Dask in Kombination mit SLURM (dem Job-Scheduler des bwUniClusters) nutzen zu können, wird entweder die Klasse SLURMCluster aus dem Modul dask_jobqueue oder das Programm dask-mpi benötigt.\n",
    "\n",
    "Für die nachfolgenden Übungen wird dask-mpi benötigt. dask_jobqueue ist daher nur grundlegend beschrieben (das in \"2_Grundlagen\" erstellte Environment wurde nur für dask-mpi vorbereitet: die weiter unten folgenden Übungen können dementsprechend nur mit dask-mpi ausgeführt werden).\n",
    "\n",
    "### dask_jobqueue\n",
    "\n",
    "__WICHTIG: dask_jobqueue setzt eine eins zu eins Beziehung zwischen Job und Node voraus. D.h. pro Job wird genau ein Node reserviert und genutzt. Werden mehrere Nodes benötigt, so sieht dask_jobqueue vor, dass entsprechend viele Jobs abgesetzt werden. Dies führt auf dem bwUniCluster zu zwei grundlegenden Problemen. Zum einen werden mehrere Jobs unabhängig voneinander gescheduled. Jeder Job hat daher einen eigenen Startzeitpunkt. Es stehen also nur mit viel Glück alle benötigten Ressourcen zeitgleich zur Verfügung. Zum anderen sehen alle multiple-Queues vor, dass pro Job mindestens zwei Nodes reserviert werden. Diese Queues sind explizit für Anwendungsfälle gedacht in denen mehrere Nodes zur gleichen Zeit benötigt werden. Werden diese Queues zusammen mit dask_jobqueue genutzt, so setzt dask_jobqueue für jeden benötigten Node einen eigenen Job ab, der jeweils zwei Nodes reserviert, von denen dask_jobqueue aber dann nur einen nutzt.__\n",
    "\n",
    "Fazit:\n",
    "- um mehrere Nodes zeitgleich zur Verfügung zu haben, sieht bwUniCluster einen Job in einer multiple-Queue mit mehreren Nodes pro Job vor\n",
    "- dask_jobqueue setzt vorraus, dass pro Job nur ein Node genutzt wird\n",
    "- anstelle von dask_jobqueue sollte dask-mpi genutzt werden\n",
    "\n",
    "\n",
    "Damit dask_jobqueue zur Verfügung steht muss im jeweiligen Environment sowohl dask als auch dask_jobqueue installiert sein:\n",
    "\n",
    "```bash\n",
    "python3 -m pip install dask_jobqueue dask\n",
    "```\n",
    "\n",
    "Ist der IPython-Kernel aus einem entsprechend erweiterten Environment im Jupyter registriert, so kann dieser beim Start eines neuen Notebooks ausgewählt werden. Anschließend kann die SLURMCluster Klasse im Notebook importiert und zum Erstellen einer SLURM-Job-Konfiguration genutzt werden.\n",
    "\n",
    "Welche queues für eine solche Konfiguration am bwUniCluster zur Verfügung stehen und welche Eigenschaften diese Haben kann der Dokumentation unter\n",
    "\n",
    "https://wiki.bwhpc.de/e/BwUniCluster_2.0_Batch_Queues\n",
    "\n",
    "entnommen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78deda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(\n",
    "    queue='multiple', # queue multiple ermöglicht eine Reservierung von mehreren Nodes pro Job (min. 2 Nodes pro Job)\n",
    "    cores=40, # ein Node der queue multiple besitzt 40 cores => für 80 cores werden zwei Nodes angefordert\n",
    "    memory=\"90GB\", # maximal verfügbarer Speicher pro Node in queue multiple\n",
    "    local_directory='/tmp', # Daten sollen lokal im Node und nicht über Netzwerk ins zentrale Filesystem geschrieben werden\n",
    "    walltime='00:30:00', # Nodes sollen eine halbe Stunde reserviert werden\n",
    "    interface='ib0' # für die Netzwerkkommunikation im Cluster wollen wir schnelles Infiniband nutzen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2daed",
   "metadata": {},
   "source": [
    "Der eigentliche Job wird dann auf Basis der Konfiguration mittels der Methode scale gestartet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=1) # beim Start der Konfiguration können auch mehrere Jobs gleichzeitig gestartet werden (hierdurch ist das Reservieren mehrerer Nodes möglich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466d918-f30c-48e1-9bcc-ecbb3e65c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client # enthält die Informationen über den gestarteten Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbbdc5-efa0-496e-9577-edcff4c11fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6dd61-188d-49d1-af83-c2cc6f500603",
   "metadata": {
    "tags": []
   },
   "source": [
    "### dask-mpi\n",
    "\n",
    "Die Anwendung dask-mpi ermöglicht das Starten eines dask-Clusters über MPI. Hierdurch ist es möglich, mehrere Nodes mit nur einem Job zu reservieren. Dadurch können auch Queues genutzt werden, die mehr als einen Node pro Job voraussetzen. Zudem ist sichergestellt, dass alle benötigten Nodes zum gleichen Zeitpunkt verfügbar sind (da sie über den gleichen Job angefordert wurden).\n",
    "\n",
    "#### Environment \n",
    "\n",
    "Für die nachfolgenden Beispiele wird das im Notebook \"2_Grundlagen\" erstellte Environment benötigt. Dieses Environment muss für dieses Notebook über den entsprechenden Kernel ausgewählt sein.\n",
    "\n",
    "Damit das im Notebook \"2_Grundlagen\" erstellte Environment schnell auf die genutzten Nodes kopiert werden kann, sollte dieses in ein Archiv gepackt werden (der folgende Befehl muss im Terminal File->New->Terminal ausgeführt werden):\n",
    "\n",
    "```bash\n",
    "tar -zcvf ~/miniconda3/envs/python_workshop_env.gz -C ~/miniconda3/envs/ python_workshop_env/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f5d06-cc0a-4e18-a1d4-98282f18ecac",
   "metadata": {},
   "source": [
    "#### sbatch und Job-Script\n",
    "\n",
    "Zum Starten eines dask-Clusters über dask-mpi wird ein Job-Script benötigt. Dieses wird später über sbatch gestartet. Sbatch sorgt dafür, dass die benötigte Anzahl an Knoten reserviert wird (dabei wird auch festgelegt, wieviele Tasks gestartet werden sollen und wie diese über die Nodes verteilt werden sollen). Nachdem die angeforderten Knoten verfügbar sind, führt sbatch das übergebene Script auf dem ersten der reservierten Nodes aus. In diesem Script können dann benötigte Daten auf die einzelnen Nodes kopiert werden (über separate Jobs, welche per srun gestartet werden; lokale Daten können im Vergleich zu Zugriffen auf das zentrale File System schneller eingelesen werden). Abschließend führt das Script einen Aufruf von mpirun aus. Über mpirun wird dask-mpi n mal gestartet. Dabei sollte n gleich der Anzahl der benötigten Worker plus eins (für den Scheduler) sein. Die Anzahl n muss dabei zur Anzahl der über sbatch konfigurierten Tasks passen.\n",
    "\n",
    "#### Anzahl Prozesse pro Node und Anzahl Threads pro Prozess:\n",
    "\n",
    "Pro Node sollte die Anzahl der Threads pro Prozess multipliziert mit der Anzahl der Prozesse der Summe der Verfügbaren Cores entsprechen. Nur so ist gewährleistet, dass alle Threads einen Core verfügbar haben und nicht durch andere Threads ausgebremst werden. Wenn einzelne Tasks Wartezeiten beinhalten (z.B. warten auf File-I/O oder warten auf Ergebnisse anderer Tasks) kann es allerdings besser sein, mehr parallel laufende Tasks (Prozesse oder Threads) als Cores verfügbar sind einzuplanen.\n",
    "\n",
    "Informationen über die Queues: https://wiki.bwhpc.de/e/BwUniCluster_2.0_Batch_Queues\n",
    "\n",
    "Informationen über die Hardware pro Node: https://wiki.bwhpc.de/e/BwUniCluster_2.0_Hardware_and_Architecture\n",
    "\n",
    "Bei überwiegender Nutzung von numerischen Bibliotheken ist eine hohe Anzahl von Threads pro Prozess sinnvoll, da diese Bibliotheken (Numpy, Pandas, ...) so implementiert sind, dass sie nicht vom Global Interpreter Lock (GIL) von Python ausgebremst werden. Sie sind meist in C geschrieben und bieten nur ein Interface für Zugriffe aus Python. Gleichzeitig profitieren sie von der gemeinsamen Nutzung der selben Daten innerhalb eines Prozesses (keine Interprozesskommunikation zwischen Threads im gleichen Prozess nötig).\n",
    "\n",
    "Werden hauptsächlich in Python geschriebene Algorithmen ausgeführt, so bieten sich viele Prozess mit wenigen oder gar nur je einem Thread pro Prozess an, da das GIL hier eine parallele Ausführung mit mehreren Threads in einem Prozess verhindert.\n",
    "\n",
    "Mischungen von numerischen Bibliotheken und in Python implementierten Algorithmen machen ein ausgewogeneres Verhältnis zwischen Prozessen und Threads notwendig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5c0d5-64e5-4f97-b5d2-d0994d88b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# für die Reservierung in einer miltiple-Queue muss count_nodes mindestens 2 betragen\n",
    "count_nodes = 2\n",
    "queue = \"multiple\"\n",
    "# für die Reservierung in einer single-Queue muss count_nodes genau 1 betragen\n",
    "#count_nodes = 1\n",
    "#queue = \"single\"\n",
    "\n",
    "count_worker_per_node = 2 # auf dem ersten Node wird noch der Scheduler gestartet => der erste Node stellt einen Worker weniger zur Verfügung\n",
    "count_threads_per_worker = 20 # count_worker_per_node * count_threads_per_worker sollte der Anzahl der per Node verfügbaren Cores entsprechen (s.o.)\n",
    "time = \"30:00\" # 30 min.\n",
    "mem = \"90000mb\"\n",
    "tmp_envs_dir = f\"$TMP/envs\" # $TMP verweist auf ein lokales Verzeichnis je Node und Job (/scratch/slurm_tmpdir/job_<job-id>)\n",
    "tmp_dask_dir = f\"$TMP/dask\" # unter $TMP soll Dask Daten auslagern, sofern der Arbeitsspeicher nicht ausreicht\n",
    "\n",
    "scheduler_file = os.path.expanduser(\"~/dask-scheduler.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6336d-1ecc-40f5-b186-1cadeb814263",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_file = os.path.expanduser(\"~/job_dask_mpi.sh\")\n",
    "\n",
    "f = open(job_file, \"w\") # ein neues Script erstellen, welches dann per sbatch abgeschickt werden kann\n",
    "f.write(f\"\"\"#!/bin/bash -l\n",
    "# -l dient dazu die Einstellungen der bashrc zu übernehmen (wird für conda benötigt)\n",
    "\n",
    "# jeden über sbatch reservierten Node einzeln in einer for-Schleife durchgehen\n",
    "NODES=$(scontrol show hostname | cat)\n",
    "DASK_HOSTS=\"\"\n",
    "for NODE in $NODES\n",
    "do\n",
    "    # In single Queues fehlt die für mpirun benötigte node list, daher nutzen wir eine selbst\n",
    "    # erstellte host list (dies kann in single und multiple Queues genutzt werden).\n",
    "    # Die doppelten geschweiften Klammern sind die Escape-Sequenz für einfache geschweifte\n",
    "    # Klammern innerhalb eines Python-Format-Strings.\n",
    "    DASK_HOSTS+=\"${{NODE}},\"\n",
    "    \n",
    "    # pro Node einen Job per srun starten und Daten unter $TMP lokal im Node speichern\n",
    "    # das \"&\" am ende sorgt dafür, dass der srun parallel im Hintergrund ausgeführt wird\n",
    "    # der \"\\\" am Zeilenende maskiert das Zielenende (nächste Zeile gehört noch zur aktuellen Zeile)\n",
    "    # rm -rf löscht ein Verzeichnis\n",
    "    # mkdir erstellt ein Verzeichnis\n",
    "    # cp kopiert eine Datei\n",
    "    # tar entpackt die Datei\n",
    "    # das \"&&\" zwischen den einzelnen Befehlen sorgt dafür, dass die folgenden Befehle nur ausgeführt\n",
    "    #    werden, wenn der vorhergehende Befehl erfolgreich war (er gab keinen Fehler zurück)\n",
    "    srun -N 1 -n 1 -w $NODE /bin/bash -c \"\\\n",
    "        rm -rf {tmp_envs_dir} && \\\n",
    "        rm -rf {tmp_dask_dir} && \\\n",
    "        mkdir -p {tmp_envs_dir} && \\\n",
    "        mkdir -p {tmp_dask_dir} && \\\n",
    "        cp ~/miniconda3/envs/python_workshop_env.gz {tmp_envs_dir} && \\\n",
    "        tar -zxf {tmp_envs_dir}/python_workshop_env.gz --directory {tmp_envs_dir} \\\n",
    "        \" &\n",
    "done\n",
    "\n",
    "# warten auf alle parallel gestarteten Befehle\n",
    "wait\n",
    "\n",
    "# Aktivieren des lokalen Environments (muss nicht auf jedem Node durchgeführt werden, da die\n",
    "# entsprechenden Umgebungsvariablen per mpirun übernommen werden)\n",
    "conda activate {tmp_envs_dir}/python_workshop_env\n",
    "\n",
    "# startet die Worker und einen Scheduler auf den Nodes\n",
    "# --map-by core:PE=n: jedem Prozess sollen n cores fest zugewiesen werden\n",
    "# -np x: x = Anzahl Worker + 1 für Scheduler (x muss gleich --ntasks bei Ausführung von sbatch sein)\n",
    "# -host=$DASK_HOSTS: hosts auf denen Prozesse gestartet werden sollen\n",
    "# --scheduler-file: sobald alle Worker gestartet sind, schreibt der Scheduler in diese Datei die Verbindungsinformationen des dask-Clusters)\n",
    "# --interface='ib0': für Kommunikation zwischen den Nodes nutzen wir Infiniband\n",
    "# --local-directory={tmp_dask_dir}: wenn dask aufgrund fehlendem Arbeitsspeicher Daten auslagern muss, soll hierfür das lokale Dateisystem des jeweiligen Nodes genutzt werden\n",
    "# --worker-class=distributed.Worker: keinen überwachenden Nanny-Prozess pro Worker Prozess\n",
    "# --nthreads: Threads per Worker\n",
    "# --name: Prefix für die Benennung der Worker in diesem Job\n",
    "# --dashboard-address: der Port unter dem das Dashboard erreichbar ist (8787 ist eigentlich der Default Value, aber im aktuellen Entwicklungsstand wird dieser nicht automatisch gesetzt)\n",
    "mpirun --map-by core:PE={count_threads_per_worker} \\\n",
    "       -np {count_nodes * count_worker_per_node} \\\n",
    "       -host=$DASK_HOSTS \\\n",
    "       dask-mpi \\\n",
    "       --scheduler-file {scheduler_file} \\\n",
    "       --interface='ib0' \\\n",
    "       --local-directory={tmp_dask_dir} \\\n",
    "       --worker-class=distributed.Worker \\\n",
    "       --nthreads={count_threads_per_worker} \\\n",
    "       --name base \\\n",
    "       --dashboard-address=8787\"\"\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996d098-d4e0-459e-b59b-46ab4edcd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wie viele Nodes sind pro Queue aktuell frei verfügbar\n",
    "# kann auch in einem Terminal (File->New->Terminal) außerhalb des Jupyter Notebooks als Befehl \"sinfo_t_idle\" abgesetzt werden\n",
    "os.system(\"sinfo_t_idle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbe946-826d-4a38-ba22-f0483cf27d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm: Löschen des ~/dask-scheduler.json Files: sobald das File wieder da ist, ist der angeforderte Dask-Cluster gestartet\n",
    "# sbatch: reserviert die notwendigen Ressourcen (Nodes) in der angegebenen queue und startet das Script ~/job_dask_mpi.sh auf dem ersten der Nodes\n",
    "os.system(f\"rm -f {scheduler_file} && \\\n",
    "            sbatch \\\n",
    "            -p {queue} \\\n",
    "            --nodes={count_nodes} \\\n",
    "            --ntasks={count_nodes * count_worker_per_node} \\\n",
    "            --ntasks-per-node={count_worker_per_node} \\\n",
    "            --time={time} \\\n",
    "            --mem={mem} \\\n",
    "            {job_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf484ad-3205-4111-b98b-abfb3294db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steht bereits ein Zeitpunkt fest, an dem die Ressourcen für uns verfügbar sind?\n",
    "os.system(\"squeue --start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c391c8-4548-4fa2-bd5b-24aaf3c3103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# welche Ressourcen sind für unseren User angefordert?\n",
    "# Zeigt eine Zeile pro Job mit dem Ressourcen angefordert wurden.\n",
    "# ST: Status\n",
    "#     PD: Pending, Ressourcen wurden angefordert, stehen aber noch nicht zur Verfügung\n",
    "#     R:  Running, Ressourcen sind verfügbar\n",
    "#     CG: Completing, Job ist beendet/abgebrochen, allerdings laufen noch einzelne Prozesse (die noch beendet oder abgebrochen werden)\n",
    "#     weitere Status-Codes: https://curc.readthedocs.io/en/latest/running-jobs/squeue-status-codes.html\n",
    "# TIME: wie lange sind die Ressourcen schon durch uns genutzt\n",
    "# NODES: Anzahl der Reservierten Nodes\n",
    "# NODELIST: welche Nodes sind Reserviert\n",
    "#     Der Namen der Nodes ist mit einem Prefix (ist für jeden Node gleich) gefolgt von der Nummerierung der einzelnen Nodes in Eckigen Klammern angegeben.\n",
    "#     Ein Bindestrich zwischen zwei Nummern in den Eckigen Klammern bedeutet, dass alle Nummern zwischen den beiden angegebenen für uns Reserviert sind.\n",
    "#     Ein Komma zwischen zwei Nummern bedeutet, dass die beiden Nummern für uns Reserviert sind.\n",
    "#     Beispiele:\n",
    "#         uc2n[001-003] zeigt an, dass uc2n001, uc2n002 und uc2n003 reserviert wurden\n",
    "#         uc2n[001,003] zeigt an, dass uc2n001 und uc2n003 reserviert wurden\n",
    "os.system(\"squeue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06cb2ac-7a8d-4030-b500-26de8a86187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time as t\n",
    "\n",
    "# warten, bis die Datei scheduler_file (~/dask-scheduler.json) vorhanden ist\n",
    "# (diese wird vom Dask-Scheduler geschrieben, sobald Worker gestartet und bereit sind)\n",
    "while not os.path.isfile(scheduler_file):\n",
    "    t.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42aac6c-6ba2-4c1a-b569-0343e04b2cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aktuller Status und Fehlermeldungen des SLURM-Jobs können über das slurm-<JOBID>.out File eingesehen werden:\n",
    "jobid = 22439085 # die JOBID muss entsprechend auf die aktuelle ID angepasst werden (s.o.)\n",
    "cwd = os.getcwd()\n",
    "f = open(cwd + \"/slurm-\" + str(jobid) + \".out\",\"r\")\n",
    "lines = f.readlines()\n",
    "display(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f377a3-0af2-46f6-be7a-21bc0f87aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Über ein Client-Objekt können wir das aktuelle Jupyter-Notebook mit dem erstellten Dask-Cluster verbinden.\n",
    "# Dafür nutzen wir die ~/dask-scheduler.json Datei. In dieser sind IP und Port des Schedulers gespeichert.\n",
    "# (anstatt aus einem Jupter-Notebook heraus, kann dies z.B. auch aus einem Python-Script heraus geschehen)\n",
    "client = Client(scheduler_file=scheduler_file)\n",
    "\n",
    "# wenn dask aufgrund fehlendem Arbeitsspeicher Daten auslagern muss, soll hierfür das lokale Dateisystem\n",
    "# des jeweiligen Nodes genutzt werden\n",
    "dask.config.set({'temporary_directory': tmp_dask_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894c66c-504d-49c8-ab98-9e81f2f93d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir lassen den Client anzeigen (dieser enthält auch Informationen zum Scheduler und den einzelnen Workern)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb826ce4-17d8-4965-b8ff-2a29b60a783a",
   "metadata": {},
   "source": [
    "### Dask Cluster nachträglich vergrößern\n",
    "\n",
    "Weitere Worker können mit einem separaten Job erstellt und dem Scheduler aus einem vorhergehenden Job hinzugefügt werden. Hierzu wird auch die scheduler-json-Datei genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16476e3-cdd0-4387-993b-d95239e02b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_file = os.path.expanduser(\"~/job_dask_mpi_2.sh\")\n",
    "\n",
    "# ein Script um einen existierenden Cluster zu erweitern\n",
    "f = open(job_file, \"w\")\n",
    "f.write(f\"\"\"#!/bin/bash -l\n",
    "NODES=$(scontrol show hostname | cat)\n",
    "DASK_HOSTS=\"\"\n",
    "for NODE in $NODES\n",
    "do\n",
    "    DASK_HOSTS+=\"${{NODE}},\"\n",
    "    \n",
    "    srun -N 1 -n 1 -w $NODE /bin/bash -c \"\\\n",
    "        rm -rf {tmp_envs_dir} && \\\n",
    "        rm -rf {tmp_dask_dir} && \\\n",
    "        mkdir -p {tmp_envs_dir} && \\\n",
    "        mkdir -p {tmp_dask_dir} && \\\n",
    "        cp ~/miniconda3/envs/python_workshop_env.gz {tmp_envs_dir} && \\\n",
    "        tar -zxf {tmp_envs_dir}/python_workshop_env.gz --directory {tmp_envs_dir} \\\n",
    "        \" &\n",
    "done\n",
    "\n",
    "wait\n",
    "\n",
    "conda activate {tmp_envs_dir}/python_workshop_env\n",
    "\n",
    "# da ein existierender Dask-Cluster erweitert werden soll:\n",
    "# --no-scheduler: erstelle keinen eigenen Scheduler, sondern registriere die Worker an dem im scheduler-file angegebenen Scheduler\n",
    "mpirun --map-by core:PE={count_threads_per_worker} \\\n",
    "       -np {count_nodes * count_worker_per_node} \\\n",
    "       -host=$DASK_HOSTS \\\n",
    "       dask-mpi \\\n",
    "       --scheduler-file {scheduler_file} \\\n",
    "       --interface='ib0' \\\n",
    "       --local-directory={tmp_dask_dir} \\\n",
    "       --worker-class=distributed.Worker \\\n",
    "       --nthreads={count_threads_per_worker} \\\n",
    "       --no-scheduler \\\n",
    "       --name expansion\"\"\")\n",
    "f.close()\n",
    "\n",
    "# einen Node über sbatch reservieren und das Script auf diesem ausführen\n",
    "os.system(f\"sbatch \\\n",
    "            -p {queue} \\\n",
    "            --nodes={count_nodes} \\\n",
    "            --ntasks={count_nodes * count_worker_per_node} \\\n",
    "            --ntasks-per-node={count_worker_per_node} \\\n",
    "            --time={time} \\\n",
    "            --mem={mem} \\\n",
    "            {job_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae8515-c194-40c2-a847-54f13cf5595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"squeue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f63e4-a29f-47c6-8eac-4dfbc540eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warten bis alle Worker verfügbar sind (aus dem ersten und aus dem zweiten Job)\n",
    "client.wait_for_workers((count_nodes * count_worker_per_node * 2) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a268b59-6895-4c61-90b6-655214a69809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir lassen den Client anzeigen (dieser enthält auch Informationen zum Scheduler und den einzelnen Workern)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859cc17-cef5-4f63-96a7-904ea4c6955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anstatt einen Client über die json Datei mit einem Dask-Cluster zu verbinden, kann auch eine IP-Adresse genutzt werden\n",
    "from distributed import Client\n",
    "# hierfür muss die IP und der PORT für die Registrierung bekannt sein (z.B. aus dem slurm-<JOBID>.out File)\n",
    "client = Client('172.26.20.82:37153')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d002c-bb8c-4ede-b4a8-613027e82b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde158da-65e4-4981-95a7-8d126a175220",
   "metadata": {},
   "source": [
    "## Beispiel Dask Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf23eb-14de-482f-9ddc-b9cef3a847cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# Erstellt ein Array mit 100000 Zeilen und 100000 Spalten.\n",
    "# Jedes Element enthält einen zufälligen Wert aus dem Intervall [0.0, 1.0).\n",
    "#\n",
    "# Das Array wird in einzelne Chunks unterteilt. Jeder Chunk wird durch\n",
    "# einen separaten Task erstellt. So kann jeder Chunk von Dask auf einen\n",
    "# anderen Worker verteilt werden.\n",
    "# Die Tasks werden erst ausgeführt, wenn mit dem Array gearbeitet wird.\n",
    "# x enthält daher kein fertiges Array, sondern lediglich die Tasks,\n",
    "# die zum Erstellen des Arrays notwendig sind.\n",
    "# Anstelle einer Vorgabe der maximalen Chunk-Größe in MiB kann auch die\n",
    "# Anzahl der Elemente pro Chunk definiert werden (siehe\n",
    "# https://docs.dask.org/en/latest/array-chunks.html).\n",
    "x = da.random.random((100000,100000), chunks=\"100 MiB\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1b62f-8380-4f61-a932-3f693ea52e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eine Rechenoperation auf einem Dask Array erstellt zunächst nur Tasks.\n",
    "# Diese werden erst ausgeführt, wenn ein Ergebnis angefordert wird.\n",
    "y = (x + x.T) - x.mean(axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa02b1c-2f30-46d2-aacf-b7ec2aca1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Methode compute() fordert ein konkretes Ergebnis an. Durch den\n",
    "# Aufruf dieser Methode werden die geplanten Tasks ausgeführt.\n",
    "y.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2189e13-d557-4c29-8508-0587fa44bbbe",
   "metadata": {},
   "source": [
    "## Beispiel Dask Dataframe und Scikit-Learn\n",
    "\n",
    "Basiert auf https://github.com/rikturr/high-performance-jupyter (MIT-License)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b44b90-0bbf-428a-bd59-64300d7f512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%time misst die Zeit, die eine Code-Zelle im Jupyter-Notebook zur Ausführung braucht\n",
    "# %%time muss in der ersten Zeile der Zelle stehen\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# erstellt Tasks um ~8 GB Daten aus einem s3 Bucket zu laden und als Dataframe einzulesen\n",
    "#taxi = dd.read_csv(\n",
    "#    's3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv',\n",
    "#    assume_missing=True, # beim Einlesen werden alle Ints zu Floats. Dies erlaubt fehlende Werte\n",
    "#    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], # interpretiert diese Spalten als Datum\n",
    "#    storage_options={'anon': True}, # für S3: keine Authentifizierung für diesen Bucket nötig\n",
    "#)\n",
    "## S3 benötigt einen AWS account, daher ist der direkte Zugriff nicht mehr möglich\n",
    "## bitte die lokal bereitgestellte parquet-Datei nutzen (siehe unten)\n",
    "\n",
    "taxi = dd.read_parquet(\n",
    "    './files/green_tripdata_2023-01.parquet',\n",
    "    engine='pyarrow'\n",
    ")\n",
    "#df = pd.read_parquet('./files/green_tripdata_2023-01.parquet', engine='pyarrow')\n",
    "taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7425c-4716-4206-919f-87f21103056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# beide folgenden Zeilen führen die in \"taxi\" enthaltenen Tasks aus,\n",
    "# um deren Ergebnis für weitere Operationen zu nutzen\n",
    "# => Einlesen in den Dataframe wird zwei mal ausgeführt!\n",
    "print(f\"Anzahl Zeilen: {len(taxi)}\") #Zeilen aller Datensätze zusammen\n",
    "print(f\"Größe in GB: {taxi.memory_usage(deep=True).sum().compute() / 1e9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fd416-8b12-47c6-945a-0515847cec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait\n",
    "\n",
    "# persist() führt alle geplanten Tasks im Hintergrund (asynchron) aus und gibt das Ergebnis zurück\n",
    "# wir ersetzen demnach hier die Tasks durch den fertigen Dataframe\n",
    "taxi = taxi.persist()\n",
    "# wait() wartet auf die im Hintergrund gestarteten Tasks\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778954e-89be-4917-9aff-fda7d13cbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# len() und memory_usage() sind deutlich schneller, wenn auf dem persistierten\n",
    "# Ergebnis der Tasks gearbeitet wird\n",
    "print(f\"Anzahl Zeilen: {len(taxi)}\") #Zeilen aller Datensätze zusammen\n",
    "print(f\"Größe in GB: {taxi.memory_usage(deep=True).sum().compute() / 1e9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b12289-cb5c-4022-9fb1-485d3a71df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feat = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "categorical_feat = [\n",
    "    'PULocationID', \n",
    "    'DOLocationID',\n",
    "]\n",
    "features = numeric_feat + categorical_feat\n",
    "y_col = 'high_tip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bcdfff-4526-4cd2-8527-04a60fa71cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = df[df.fare_amount > 0]  # nur Zeilen übernehmen, die nicht 0 sind (kein Teilen durch 0)\n",
    "    df['tip_fraction'] = df.tip_amount / df.fare_amount\n",
    "    df[y_col] = (df['tip_fraction'] > 0.2) # wenn tip_amount / fare_amount > 0.2, dann high_tip = true\n",
    "    \n",
    "    df['pickup_weekday'] = df.lpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.lpep_pickup_datetime.dt.isocalendar().week\n",
    "    df['pickup_hour'] = df.lpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.lpep_pickup_datetime.dt.minute\n",
    "    \n",
    "    # alle Eingaben für das Training in float umwandeln und nicht vorhandene Werte auf -1 setzen\n",
    "    df = df[features + [y_col]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "taxi = prep_df(taxi)\n",
    "taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5bbec-5287-4450-a0b2-bd8b8dfb9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Tasks zum Aufbereiten des Dataframes (prep_df) ausführen\n",
    "taxi = taxi.persist()\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314ae9b-8653-4d44-821a-ce6a19ff794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390e404-4f6d-4572-9052-6f2d416f7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# describe() generiert für jede Spalte eine Statistik-Übersicht (Min., Max., Quantile, ...)\n",
    "np.round(taxi.describe().compute(), 3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c2121-675d-4181-8401-3678286286a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "taxi_sample = taxi.sample(frac=0.02, replace=False, random_state=seed)\n",
    "taxi_sample = taxi_sample.persist()\n",
    "_ = wait(taxi_sample)\n",
    "\n",
    "len(taxi_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec68bc-f0b7-4255-80d2-90d35fa59a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dask_ml.compose import ColumnTransformer\n",
    "from dask_ml.preprocessing import StandardScaler, DummyEncoder, Categorizer\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    solver='saga',\n",
    "    penalty='elasticnet', \n",
    "    l1_ratio=0.5,\n",
    "    max_iter=100, \n",
    "    random_state=seed,\n",
    ")\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('categorize', Categorizer(columns=categorical_feat)),\n",
    "    ('onehot', DummyEncoder(columns=categorical_feat)),\n",
    "    ('scale', ColumnTransformer(transformers=[('num', StandardScaler(), numeric_feat)])),\n",
    "    ('clf', lr),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'clf__l1_ratio': [0.2, 0.3, 0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    params,\n",
    "    cv=3, \n",
    "    scoring='accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1584453-7c18-4820-936b-0d9c488e159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Bevor fit() aufgerufen wird, kann joblib mitgeteilt\n",
    "# werden, dass ein Dask Cluster verfügbar ist.\n",
    "# joblib wird von scikit-learn genutzt, um zu\n",
    "# parallelisieren. Dies kann hilfreich sein, sofern\n",
    "# nicht bereits Ojekte von dask_ml genutzt werden.\n",
    "#import joblib # wird benötigt, um scikit-learn mit dem Dask Cluster zu verbinden\n",
    "#with joblib.parallel_backend('dask'):\n",
    "#    _ = grid_search.fit(taxi_sample[features], taxi_sample[y_col])\n",
    "_ = grid_search.fit(taxi_sample[features], taxi_sample[y_col])\n",
    "\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85258b57-d9e6-499c-b1e7-b4257f7ed9be",
   "metadata": {},
   "source": [
    "## Funktionen als Tasks\n",
    "\n",
    "Mit dem Dekorator \"delayed\" können Funktionen beim Aufruf in Tasks umgewandelt werden. Diese Tasks werden dann von Dask ausgeführt, sobald ein Ergebnis angefordert wird. Das Einplanen und Ausführen eines Tasks erzeugt Overhead. Ein Task sollte daher immer möglichst viel Rechenaufwand enthalten. Es kann kontraproduktiv sein, Tasks möglichst klein zu halten. Das folgende Beispiel dient nur zum Verständnis von Tasks. Es enthält zu kleine Tasks. Wird der range() in der for-Schleife vergrößert, ergeben sich daraus schnell Probleme (Dask generiert Warnungen).\n",
    "\n",
    "delayed-Funktionen unterliegen Einschränkungen. Z.B. können sie nicht in einer Bedingung (if- oder Schleifen-Bedingung) genutzt werden.\n",
    "\n",
    "Weitere Informationen zu delayed: https://docs.dask.org/en/stable/delayed-api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec017db8-68b1-46d4-b499-0e45d784f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.delayed as delayed\n",
    "\n",
    "@delayed\n",
    "def increment(x):\n",
    "    return x + 1\n",
    "\n",
    "@delayed\n",
    "def power2(x):\n",
    "    return x ^ 2\n",
    "\n",
    "@delayed\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Erstellen von 10000 Tasks (bestehend aus je zwei Tasks) in einer list\n",
    "output = []\n",
    "for x in range(1, 10000):\n",
    "    a = increment(x)\n",
    "    b = power2(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "# Ein neuer Task, basierend auf der list\n",
    "total = delayed(sum)(output)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992d12e-8712-44a3-8141-1daf5fe7eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks Ausführen\n",
    "res = total.compute()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e103bc-5d3e-4f50-a3b6-d154ccf8023c",
   "metadata": {},
   "source": [
    "## Visualisierung von Dask-Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7e945-1e66-4bba-9e8c-f465b7eb749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = []\n",
    "# damit der generierte Graph übersichtlich bleibt: nur 10 Iterationen\n",
    "for x in range(1, 10):\n",
    "    a = increment(x)\n",
    "    b = power2(x)\n",
    "    c = add(a, b)\n",
    "    output2.append(c)\n",
    "\n",
    "total2 = delayed(sum)(output2)\n",
    "total2.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53c2d8-0eac-44df-a8f5-18764381fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = total2.compute()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f380296-a467-41b0-8967-cb9d4ee5d84c",
   "metadata": {},
   "source": [
    "## Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27a113-eece-4434-a37f-28b9680bb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close() # ProgressBar funktioniert nur, wenn kein Dask Cluster aktiv verbunden ist\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    res = total.compute()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4476a-c74f-4b46-9c54-7a7fcb2f13c8",
   "metadata": {},
   "source": [
    "## Ressourcen freigeben (Jobs beenden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d9720-5955-4310-90c8-05674d6ec7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# werden Ressourcen nicht länger gebraucht, so muss der zugehörige Job beendet werden,\n",
    "# um die Ressourcen (Nodes) wieder freizugeben.\n",
    "job_id = ????????\n",
    "#job_id = 22439198\n",
    "os.system(f\"scancel {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce85f8-285b-4fbd-9d18-458b0b5af3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_workshop_env",
   "language": "python",
   "name": "python_workshop_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
